version: "3.8"
services:
  triton:
    image: nvcr.io/nvidia/tritonserver:24.08-py3
    command: [ "tritonserver", "--model-repository=/models" ]
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    environment:
      NVIDIA_VISIBLE_DEVICES: all
    volumes:
      - ./delivery-kit:/kits:ro
      # Update <pid> before running or bind a specific kit path
      - ./delivery-kit/<pid>/runtime/triton:/models:ro
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
